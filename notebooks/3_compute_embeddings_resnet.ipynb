{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5df6909",
   "metadata": {},
   "source": [
    "# 3_compute_embeddings_resnet\n",
    "\n",
    "Genera embeddings de imagen con ResNet50 (Imagenet) para comparar frente a CLIP.\n",
    "Entrada: `notebooks/data/step_2/products_clean_*.jsonl|parquet`\n",
    "Salida: intermedios en `notebooks/data/step_3/` y fichero final `data/products.jsonl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4beeaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "try:\n",
    "    from tqdm.auto import tqdm\n",
    "except ImportError:\n",
    "    tqdm = lambda x, **k: x\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parent if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
    "STEP2_DIR = PROJECT_ROOT / \"notebooks\" / \"data\" / \"step_2\"\n",
    "STEP3_DIR = PROJECT_ROOT / \"notebooks\" / \"data\" / \"step_3\"\n",
    "STEP3_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Copias intermedias (no van a git)\n",
    "STEP3_JSONL = STEP3_DIR / \"products_with_embeddings_resnet.jsonl\"\n",
    "STEP3_TXT_NPY = STEP3_DIR / \"emb_text.npy\"\n",
    "STEP3_IMG_NPY = STEP3_DIR / \"emb_img_resnet.npy\"\n",
    "\n",
    "# Copia final ligera para la web (solo campos necesarios, sin embeddings)\n",
    "FINAL_JSONL = PROJECT_ROOT / \"data\" / \"products.jsonl\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955d8792",
   "metadata": {},
   "source": [
    "## Embeddings de texto\n",
    "Se cargan de products.jsonl si existe; si no, se simulan a ceros para no mezclar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4afe170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepara embeddings de texto: si no hay df cargado, lo cargamos desde step_2\n",
    "try:\n",
    "    df\n",
    "except NameError:\n",
    "    candidates = sorted(STEP2_DIR.glob(\"products_clean*.parquet\")) or sorted(STEP2_DIR.glob(\"products_clean*.jsonl\"))\n",
    "    if not candidates:\n",
    "        raise FileNotFoundError(f\"No hay products_clean en {STEP2_DIR}. Ejecuta el notebook 2\")\n",
    "    INPUT_PATH = candidates[0]\n",
    "    if INPUT_PATH.suffix == \".parquet\":\n",
    "        df = pd.read_parquet(INPUT_PATH)\n",
    "    else:\n",
    "        df = pd.DataFrame([json.loads(l) for l in INPUT_PATH.read_text(encoding=\"utf-8\").splitlines() if l.strip()])\n",
    "    print(f\"df cargado desde {INPUT_PATH}\")\n",
    "\n",
    "emb_text = np.zeros((len(df), 1), dtype=\"float32\")\n",
    "clip_path = PROJECT_ROOT / \"data\" / \"products.jsonl\"\n",
    "if clip_path.exists():\n",
    "    try:\n",
    "        recs = [json.loads(l) for l in clip_path.read_text(encoding=\"utf-8\").splitlines() if l.strip()]\n",
    "        if recs and \"emb_text\" in recs[0]:\n",
    "            emb_text = np.array([r.get(\"emb_text\", [0]) for r in recs], dtype=\"float32\")\n",
    "            print(f\"emb_text importado desde {clip_path} {emb_text.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"No se pudo importar emb_text desde products.jsonl: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a98af3",
   "metadata": {},
   "source": [
    "## Embeddings de imagen (ResNet50 Imagenet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d214112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emb_img shape: (2000, 2048)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import io, requests, torch\n",
    "    from PIL import Image\n",
    "    from torchvision import models, transforms\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    resnet = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
    "    resnet = torch.nn.Sequential(*(list(resnet.children())[:-1])).to(device).eval()\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    def load_image(url: str):\n",
    "        try:\n",
    "            r = requests.get(url, timeout=10)\n",
    "            r.raise_for_status()\n",
    "            return Image.open(io.BytesIO(r.content)).convert(\"RGB\")\n",
    "        except Exception:\n",
    "            return Image.new(\"RGB\", (224, 224), color=(0, 0, 0))\n",
    "\n",
    "    vecs = []\n",
    "    for url in tqdm(df[\"image_url\"].fillna(\"\").tolist(), desc=\"ResNet50\"):\n",
    "        img = load_image(url)\n",
    "        with torch.no_grad():\n",
    "            t = preprocess(img).unsqueeze(0).to(device)\n",
    "            v = resnet(t).flatten().cpu().numpy()\n",
    "        vecs.append(v)\n",
    "    emb_img = np.stack(vecs)\n",
    "    # normalizar\n",
    "    norms = np.linalg.norm(emb_img, axis=1, keepdims=True) + 1e-9\n",
    "    emb_img = emb_img / norms\n",
    "    print(\"emb_img shape:\", emb_img.shape)\n",
    "except Exception as e:\n",
    "    print(\"⚠️ ResNet no disponible; usando emb_img de ceros\", e)\n",
    "    emb_img = np.zeros((len(df), 1), dtype=\"float32\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638c36e9",
   "metadata": {},
   "source": [
    "## Guardar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e4d33ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado JSONL final: /Users/marc/Documents/Projectes/tfm-product-matching/data/products.jsonl\n",
      "Intermedios en: /Users/marc/Documents/Projectes/tfm-product-matching/notebooks/data/step_3/products_with_embeddings_resnet.jsonl\n"
     ]
    }
   ],
   "source": [
    "df_out = df.copy()\n",
    "\n",
    "# Alineamos longitudes para evitar desajustes\n",
    "len_df = len(df_out)\n",
    "# Fallback si emb_img no está definido (por ejecución parcial)\n",
    "if 'emb_img' not in locals():\n",
    "    IMG_DIM = 2048\n",
    "    emb_img = [np.zeros((IMG_DIM,), dtype=\"float32\") for _ in range(len_df)]\n",
    "\n",
    "len_txt = len(emb_text)\n",
    "len_img = len(emb_img)\n",
    "min_len = min(len_df, len_txt, len_img)\n",
    "\n",
    "# Convertir a numpy (por si vienen como tensores)\n",
    "try:\n",
    "    import numpy as np\n",
    "    emb_text_arr = np.asarray([e.cpu().numpy() if hasattr(e, 'cpu') else e for e in emb_text[:min_len]])\n",
    "    emb_img_arr  = np.asarray([e.cpu().numpy() if hasattr(e, 'cpu') else e for e in emb_img[:min_len]])\n",
    "except Exception:\n",
    "    emb_text_arr = emb_text[:min_len]\n",
    "    emb_img_arr  = emb_img[:min_len]\n",
    "\n",
    "if len_df != min_len:\n",
    "    df_out = df_out.iloc[:min_len].copy()\n",
    "\n",
    "df_out[\"emb_text\"] = [e.tolist() for e in emb_text_arr]\n",
    "df_out[\"emb_img\"]  = [e.tolist() for e in emb_img_arr]\n",
    "\n",
    "# Guardado intermedio en step_3 (con embeddings)\n",
    "with open(STEP3_JSONL, \"w\", encoding=\"utf-8\") as f:\n",
    "    for rec in df_out.to_dict(orient=\"records\"):\n",
    "        f.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n",
    "np.save(STEP3_TXT_NPY, emb_text_arr)\n",
    "np.save(STEP3_IMG_NPY, emb_img_arr)\n",
    "\n",
    "# Copia final ligera para la web (sin embeddings, solo campos necesarios)\n",
    "FINAL_JSONL.parent.mkdir(parents=True, exist_ok=True)\n",
    "df_web = df_out.drop(columns=[\"emb_text\", \"emb_img\"], errors=\"ignore\")\n",
    "with open(FINAL_JSONL, \"w\", encoding=\"utf-8\") as f:\n",
    "    for rec in df_web.to_dict(orient=\"records\"):\n",
    "        f.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n",
    "print(\"Guardado JSONL final:\", FINAL_JSONL)\n",
    "print(\"Intermedios en:\", STEP3_JSONL)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env_tfm_product_matching (3.12.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
