{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3_compute_embeddings\n",
    "\n",
    "Genera embeddings de texto e imagen a partir de `products_clean`.\n",
    "Este notebook es tolerante a dependencias ausentes (cae a embeddins simulados y salta parquet si no hay pyarrow)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "try:\n",
    "    from tqdm.auto import tqdm\n",
    "except ImportError:\n",
    "    print(\"⚠️ tqdm no instalado; sin barra de progreso. `pip install tqdm` para activarla.\")\n",
    "    tqdm = lambda x, **k: x\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parent if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
    "STEP2_DIR = PROJECT_ROOT / \"notebooks\" / \"data\" / \"step_2\"\n",
    "FINAL_PARQUET = PROJECT_ROOT / \"data\" / \"products_with_embeddings.parquet\"\n",
    "FINAL_JSONL = PROJECT_ROOT / \"data\" / \"products_with_embeddings.jsonl\"\n",
    "IMAGES_CACHE = PROJECT_ROOT / \"notebooks\" / \"data\" / \"images_cache\"\n",
    "IMAGES_CACHE.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "candidates = sorted(STEP2_DIR.glob(\"products_clean_*.parquet\")) or sorted(STEP2_DIR.glob(\"products_clean_*.jsonl\"))\n",
    "if not candidates:\n",
    "    raise FileNotFoundError(f\"No hay products_clean en {STEP2_DIR}. Ejecuta 2_preparacion_productos.ipynb.\")\n",
    "INPUT_PATH = candidates[0]\n",
    "print(f\"Usando {INPUT_PATH.name}\")\n",
    "\n",
    "if INPUT_PATH.suffix == \".parquet\":\n",
    "    df = pd.read_parquet(INPUT_PATH)\n",
    "else:\n",
    "    records = [json.loads(line) for line in INPUT_PATH.read_text(encoding=\"utf-8\").splitlines() if line.strip()]\n",
    "    df = pd.DataFrame.from_records(records)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings de texto (fallback si no hay sentence-transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    texts = df[\"text_for_embedding\"].fillna(\"\").tolist()\n",
    "    emb_text = model.encode(texts, batch_size=64, convert_to_numpy=True, show_progress_bar=True, normalize_embeddings=True)\n",
    "    print(\"emb_text shape:\", emb_text.shape)\n",
    "except Exception as e:\n",
    "    print(\"⚠️ sentence-transformers no disponible, usando emb_text simulados (ceros)\")\n",
    "    print(e)\n",
    "    emb_text = np.zeros((len(df), 1), dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings de imagen (opcional; fallback a ceros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_img = np.zeros((len(df), 1), dtype=\"float32\")  # fallback por defecto\n",
    "try:\n",
    "    import io, requests\n",
    "    from PIL import Image\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    img_model = SentenceTransformer(\"clip-ViT-B-32\")\n",
    "\n",
    "    def load_image(url: str):\n",
    "        try:\n",
    "            resp = requests.get(url, timeout=10)\n",
    "            resp.raise_for_status()\n",
    "            return Image.open(io.BytesIO(resp.content)).convert(\"RGB\")\n",
    "        except Exception:\n",
    "            return Image.new(\"RGB\", (224, 224), color=(0, 0, 0))\n",
    "\n",
    "    images = [load_image(url) for url in tqdm(df[\"image_url\"].fillna(\"\").tolist(), desc=\"img\")]\n",
    "    emb_img = img_model.encode(images, batch_size=32, convert_to_numpy=True, show_progress_bar=True, normalize_embeddings=True)\n",
    "    print(\"emb_img shape:\", emb_img.shape)\n",
    "except Exception as e:\n",
    "    print(\"⚠️ Embeddings de imagen omitidos (usa fallback de ceros). Instala pillow/requests/sentence-transformers si quieres usarlos.\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardado (JSONL siempre; parquet si pyarrow está disponible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asegurar tipos serializables\n",
    "df_out = df.copy()\n",
    "df_out[\"emb_text\"] = list(emb_text)\n",
    "df_out[\"emb_img\"] = list(emb_img)\n",
    "\n",
    "parquet_ok = False\n",
    "try:\n",
    "    import pyarrow  # noqa: F401\n",
    "    df_out.to_parquet(FINAL_PARQUET, index=False)\n",
    "    parquet_ok = True\n",
    "except Exception as e:\n",
    "    print(\"⚠️ Parquet no guardado; se continua con JSONL/NPY.\")\n",
    "    print(e)\n",
    "\n",
    "# Serializar embeddings a listas para JSON\n",
    "df_json = df_out.copy()\n",
    "df_json[\"emb_text\"] = df_json[\"emb_text\"].apply(lambda x: x.tolist() if hasattr(x, \"tolist\") else list(x))\n",
    "df_json[\"emb_img\"] = df_json[\"emb_img\"].apply(lambda x: x.tolist() if hasattr(x, \"tolist\") else list(x))\n",
    "\n",
    "with open(FINAL_JSONL, \"w\", encoding=\"utf-8\") as f:\n",
    "    for rec in df_json.to_dict(orient=\"records\"):\n",
    "        f.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "# Guardado npy\n",
    "np.save(PROJECT_ROOT / \"data\" / \"emb_text.npy\", np.array(df_json[\"emb_text\"].tolist()))\n",
    "np.save(PROJECT_ROOT / \"data\" / \"emb_img.npy\", np.array(df_json[\"emb_img\"].tolist()))\n",
    "\n",
    "if parquet_ok:\n",
    "    print(\"Guardado Parquet:\", FINAL_PARQUET)\n",
    "else:\n",
    "    print(\"Parquet omitido\")\n",
    "print(\"Guardado JSONL:\", FINAL_JSONL)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.env_similaritify)",
   "language": "python",
   "name": "similaritify"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
