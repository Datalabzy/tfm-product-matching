{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4b_add_noise: generar variante con ruido\n",
    "\n",
    "Crea una versión \"noisy\" de los ficheros de Smart Connections añadiendo N distractores por cliente. Útil para pruebas de contraste y evaluación.\n",
    "\n",
    "- Entrada: `data/matchings_products.jsonl`, `data/matchings_pairs.jsonl`\n",
    "- Salida: **sobrescribe** `data/matchings_products.jsonl` y `data/matchings_pairs.jsonl` (guarda ruido). Ejecuta de nuevo el paso 4 si quieres volver a la versión “gold”.\n",
    "- Similaridad: coseno sobre embedding ligero (hash BOW 256D) de título+descripción.\n",
    "- Marca `is_distractor=True` en los productos añadidos.\n",
    "- Reproducible: semilla fija 42.\n",
    "\n",
    "Parámetro principal: `NUM_DISTRACTORS` (por defecto 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7c545a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK. Escritos 10000 productos en /Users/marc/Documents/Projectes/tfm-product-matching/data/matchings_products.jsonl\n",
      "OK. Escritos 8000 pares en /Users/marc/Documents/Projectes/tfm-product-matching/data/matchings_pairs.jsonl\n",
      "Nota: has sobrescrito los ficheros por defecto con la variante con ruido. Ejecuta 4_smart_connections de nuevo para recuperar la versión gold.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "import json, math, random\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "try:\n",
    "    PROJECT_ROOT = Path(__file__).resolve().parents[1]\n",
    "except NameError:\n",
    "    # Ejecutado desde notebook: partimos del directorio notebooks/\n",
    "    PROJECT_ROOT = Path.cwd().resolve().parents[0]\n",
    "    if not (PROJECT_ROOT / \"data\").exists() and len(PROJECT_ROOT.parents) > 0:\n",
    "        PROJECT_ROOT = PROJECT_ROOT.parent\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "\n",
    "PRODUCTS_IN = DATA_DIR / \"matchings_products.jsonl\"\n",
    "PAIRS_IN = DATA_DIR / \"matchings_pairs.jsonl\"\n",
    "PRODUCTS_OUT = DATA_DIR / \"matchings_products.jsonl\"  # sobrescribe\n",
    "PAIRS_OUT = DATA_DIR / \"matchings_pairs.jsonl\"        # sobrescribe\n",
    "\n",
    "VECTOR_SIZE = 256\n",
    "NUM_DISTRACTORS = 3  # cambia si quieres más/menos ruido\n",
    "\n",
    "def hash_token(token: str) -> int:\n",
    "    h = 0\n",
    "    for ch in token:\n",
    "        h = (h << 5) - h + ord(ch)\n",
    "        h &= 0xFFFFFFFF\n",
    "    return abs(h)\n",
    "\n",
    "def embed_text(text: str) -> List[float]:\n",
    "    vec = [0.0] * VECTOR_SIZE\n",
    "    tokens = text.lower().replace(\"[^\\\\w\\\\s]\", \" \").replace(\"\\n\", \" \").split()\n",
    "    for t in tokens:\n",
    "        idx = hash_token(t) % VECTOR_SIZE\n",
    "        vec[idx] += 1.0\n",
    "    norm = math.sqrt(sum(v * v for v in vec)) or 1.0\n",
    "    return [v / norm for v in vec]\n",
    "\n",
    "def cosine(a: List[float], b: List[float]) -> float:\n",
    "    return sum(x*y for x, y in zip(a, b))\n",
    "\n",
    "def read_jsonl(path: Path) -> List[Dict[str, Any]]:\n",
    "    rows = []\n",
    "    if not path.exists():\n",
    "        return rows\n",
    "    with path.open() as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            try:\n",
    "                rows.append(json.loads(line))\n",
    "            except Exception:\n",
    "                continue\n",
    "    return rows\n",
    "\n",
    "def write_jsonl(path: Path, rows: List[Dict[str, Any]]):\n",
    "    with path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        for r in rows:\n",
    "            f.write(json.dumps(r, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "# ---\n",
    "products = read_jsonl(PRODUCTS_IN)\n",
    "pairs = read_jsonl(PAIRS_IN)\n",
    "by_id = {p[\"id\"]: p for p in products}\n",
    "clients = [p for p in products if p.get(\"source\") == \"client\"]\n",
    "competitors = [p for p in products if p.get(\"source\") == \"competitor\"]\n",
    "\n",
    "# índice de pares existentes por cliente\n",
    "by_client = {}\n",
    "for pair in pairs:\n",
    "    cid = pair[\"client_id\"]\n",
    "    by_client.setdefault(cid, set()).add(pair[\"competitor_id\"])\n",
    "\n",
    "new_pairs = list(pairs)\n",
    "new_products = list(products)\n",
    "next_pair_id = max((p.get(\"pair_id\", 0) for p in pairs), default=0) + 1\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "for client in clients:\n",
    "    cid = client[\"id\"]\n",
    "    used = by_client.get(cid, set())\n",
    "    client_vec = embed_text(f\"{client.get('title','')} {client.get('description','')}\")\n",
    "\n",
    "    pool = [c for c in competitors if c[\"id\"] not in used]\n",
    "    random.shuffle(pool)\n",
    "    picked = 0\n",
    "\n",
    "    for comp in pool:\n",
    "        if picked >= NUM_DISTRACTORS:\n",
    "            break\n",
    "        comp_vec = embed_text(f\"{comp.get('title','')} {comp.get('description','')}\")\n",
    "        sim = cosine(client_vec, comp_vec)\n",
    "        # guardamos el score de similitud crudo; marcamos distractor\n",
    "        new_products.append({**comp, \"is_distractor\": True, \"score\": sim, \"similarity\": sim * 100})\n",
    "        new_pairs.append({\"pair_id\": next_pair_id, \"client_id\": cid, \"competitor_id\": comp[\"id\"]})\n",
    "        next_pair_id += 1\n",
    "        picked += 1\n",
    "\n",
    "write_jsonl(PRODUCTS_OUT, new_products)\n",
    "write_jsonl(PAIRS_OUT, new_pairs)\n",
    "\n",
    "print(f\"OK. Escritos {len(new_products)} productos en {PRODUCTS_OUT}\")\n",
    "print(f\"OK. Escritos {len(new_pairs)} pares en {PAIRS_OUT}\")\n",
    "print(\"Nota: has sobrescrito los ficheros por defecto con la variante con ruido. Ejecuta 4_smart_connections de nuevo para recuperar la versión gold.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env_tfm_product_matching (3.12.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
