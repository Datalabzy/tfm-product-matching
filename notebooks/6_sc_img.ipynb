{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85878ec3",
   "metadata": {},
   "source": [
    "# smart_connections_img_resnet\n",
    "\n",
    "Calcula embeddings de imagen para Smart Connections con ResNet50 (ImageNet) y recalcula los scores combinando texto+imagen.\n",
    "\n",
    "Orden sugerido:\n",
    "1. Ejecuta `smart_connections_embeddings.ipynb` (texto) para generar `matchings_text.npy` y actualizar `matchings_pairs.jsonl` con score_text.\n",
    "2. Ejecuta este notebook para generar `matchings_img_resnet.npy`, combinar scores (0.7 texto / 0.3 imagen) y sobrescribir `matchings_pairs.jsonl`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e60f787",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marc/Documents/Projectes/tfm-product-matching/.env_tfm_product_matching/lib/python3.12/site-packages/PIL/Image.py:1034: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings imagen guardados en /Users/marc/Documents/Projectes/tfm-product-matching/data/matchings_img_resnet.npy; faltantes: 781\n",
      "Mean score label=1: 0.5799 | label=0: 0.1884\n",
      "Caso Garmin:\n",
      "pair 0 label=1 score=0.7837 (t=0.7750, i=0.8038) comp=831121\n",
      "pair 2000 label=0 score=0.1312 (t=0.1524, i=0.0817) comp=178374\n",
      "pair 1 label=1 score=0.7551 (t=0.7145, i=0.8497) comp=1143212\n",
      "pair 2001 label=0 score=0.1971 (t=0.1943, i=0.2036) comp=574333\n",
      "Pares actualizados en /Users/marc/Documents/Projectes/tfm-product-matching/data/matchings_pairs.jsonl. Recarga la API con ?nocache=1\n"
     ]
    }
   ],
   "source": [
    "# smart_connections_img_resnet\n",
    "from __future__ import annotations\n",
    "import json, math, io\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Any\n",
    "import requests\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from torchvision import models\n",
    "\n",
    "ALPHA = 0.7  # peso texto; 1-ALPHA imagen\n",
    "\n",
    "try:\n",
    "    PROJECT_ROOT = Path(__file__).resolve().parents[1]\n",
    "except NameError:\n",
    "    PROJECT_ROOT = Path.cwd().resolve().parents[0]\n",
    "    if not (PROJECT_ROOT / \"data\").exists() and len(PROJECT_ROOT.parents) > 0:\n",
    "        PROJECT_ROOT = PROJECT_ROOT.parent\n",
    "\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "PROD_PATH = DATA_DIR / \"matchings_products.jsonl\"\n",
    "PAIR_PATH = DATA_DIR / \"matchings_pairs.jsonl\"\n",
    "TEXT_EMB = DATA_DIR / \"matchings_text.npy\"\n",
    "IMG_EMB = DATA_DIR / \"matchings_img_resnet.npy\"\n",
    "INDEX_PATH = DATA_DIR / \"matchings_index.json\"\n",
    "\n",
    "assert PROD_PATH.exists(), \"Falta matchings_products.jsonl\"\n",
    "assert PAIR_PATH.exists(), \"Falta matchings_pairs.jsonl\"\n",
    "assert TEXT_EMB.exists(), \"Ejecuta primero 4_smart_connections_text.ipynb\"\n",
    "assert INDEX_PATH.exists(), \"Falta index de ids\"\n",
    "\n",
    "# Carga datos\n",
    "products = [json.loads(line) for line in PROD_PATH.read_text().splitlines() if line.strip()]\n",
    "pairs = [json.loads(line) for line in PAIR_PATH.read_text().splitlines() if line.strip()]\n",
    "ids = json.loads(INDEX_PATH.read_text())[\"ids\"]\n",
    "id_to_idx = {pid: i for i, pid in enumerate(ids)}\n",
    "text_emb = np.load(TEXT_EMB)\n",
    "assert text_emb.shape[0] == len(ids)\n",
    "\n",
    "# Modelo ResNet50\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2).to(device)\n",
    "model.fc = torch.nn.Identity()\n",
    "model.eval()\n",
    "\n",
    "preprocess = T.Compose([\n",
    "    T.Resize(256),\n",
    "    T.CenterCrop(224),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "img_embs = np.zeros((len(ids), 2048), dtype=np.float32)\n",
    "session = requests.Session()\n",
    "\n",
    "def fetch_image(url: str):\n",
    "    try:\n",
    "        r = session.get(url, timeout=5)\n",
    "        r.raise_for_status()\n",
    "        img = Image.open(io.BytesIO(r.content)).convert(\"RGB\")\n",
    "        return img\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "@torch.no_grad()\n",
    "def embed_image(img: Image.Image) -> np.ndarray:\n",
    "    x = preprocess(img).unsqueeze(0).to(device)\n",
    "    vec = model(x).cpu().numpy()[0]\n",
    "    norm = np.linalg.norm(vec) or 1.0\n",
    "    return vec / norm\n",
    "\n",
    "missing = 0\n",
    "for idx, pid in enumerate(ids):\n",
    "    prod = products[idx]\n",
    "    url = prod.get(\"image_url\") or prod.get(\"image\")\n",
    "    if not url:\n",
    "        missing += 1\n",
    "        continue\n",
    "    img = fetch_image(url)\n",
    "    if img is None:\n",
    "        missing += 1\n",
    "        continue\n",
    "    img_embs[idx] = embed_image(img)\n",
    "\n",
    "np.save(IMG_EMB, img_embs)\n",
    "print(f\"Embeddings imagen guardados en {IMG_EMB}; faltantes: {missing}\")\n",
    "\n",
    "scored = []\n",
    "for pair in pairs:\n",
    "    ci = id_to_idx.get(pair[\"client_id\"])\n",
    "    cj = id_to_idx.get(pair[\"competitor_id\"])\n",
    "    score_t = float(np.dot(text_emb[ci], text_emb[cj])) if ci is not None and cj is not None else 0.0\n",
    "    score_i = float(np.dot(img_embs[ci], img_embs[cj])) if ci is not None and cj is not None else 0.0\n",
    "    score = ALPHA * score_t + (1-ALPHA) * score_i\n",
    "    pair[\"score_text\"] = score_t\n",
    "    pair[\"score_image\"] = score_i\n",
    "    pair[\"score\"] = score\n",
    "    pair[\"similarity\"] = score * 100\n",
    "    if \"label\" not in pair:\n",
    "        pair[\"label\"] = 1\n",
    "    if \"is_distractor\" not in pair:\n",
    "        pair[\"is_distractor\"] = pair.get(\"label\",1)==0\n",
    "    scored.append(pair)\n",
    "\n",
    "pos = [p[\"score\"] for p in scored if p.get(\"label\") == 1]\n",
    "neg = [p[\"score\"] for p in scored if p.get(\"label\") == 0]\n",
    "print(f\"Mean score label=1: {sum(pos)/max(len(pos),1):.4f} | label=0: {sum(neg)/max(len(neg),1):.4f}\")\n",
    "\n",
    "cl = next((p for p in products if \"garmin quatix 7x solar watch\".lower() in p.get(\"title\",\"\").lower()), None)\n",
    "if cl:\n",
    "    print(\"Caso Garmin:\")\n",
    "    for pair in scored:\n",
    "        if pair[\"client_id\"] != cl[\"id\"]:\n",
    "            continue\n",
    "        print(f\"pair {pair['pair_id']} label={pair['label']} score={pair['score']:.4f} (t={pair['score_text']:.4f}, i={pair['score_image']:.4f}) comp={pair['competitor_id']}\")\n",
    "\n",
    "PAIR_PATH.write_text(\"\\n\".join(json.dumps(r, ensure_ascii=False) for r in scored))\n",
    "print(f\"Pares actualizados en {PAIR_PATH}. Recarga la API con ?nocache=1\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env_tfm_product_matching (3.12.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
